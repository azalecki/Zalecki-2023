---
title: "Analysis of Neighborhood Characteristics of Library Catchment Areas in Chicago, IL"
author: "Alexandra Ola Zalecki"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---

# Abstract

Rising inequality and increased privatization of space in urban landscapes is bringing attention to some of the only public spaces left: libraries. This study analyzes to what extent library service areas differ along lines of inequality like race, class, etc. This study will delineate library catchment areas in Chicago, IL and compare them with socio-economic data at the tract and block level. This analysis is the first part of a two pronged methods that aims to answer the question of to what extent the catchment areas are distinct. 

## Study Metadata

- `Key words`: public space, library programs, inequality, gis
- `Subject`: Social and Behavioral Sciences: Geography: Human Geography
- `Date created`: 11/28/2023
- `Date modified`: 12/5/2023
- `Spatial Coverage`: Chicago, IL
- `Spatial Resolution`: Census Tracts, Census Blocks, Library Service Areas
- `Spatial Reference System`: EPSG:32616 
- `Temporal Coverage`: 2017-Present
- `Temporal Resolution`: Specify the temporal resolution of your study---i.e. the duration of time for which each observation represents or the revisit period for repeated observations

# Study design

This study is a reproduction of my own **an original study**. As part of my independent research work with Professor Peter Nelson, I created a workflow in QGIS to answer the question: How do library service catchment areas differ along lines of race, class, gender, etc? In order to streamline this research and make it reproducible/replicable I decided to reproduce the workflow in R and create a research compendium for it as part of my final independent project in GEOG0361: Open GIScience.

Enumerate specific **hypotheses** to be tested or **research questions** to be investigated here, and specify the type of method, statistical test or model to be used on the hypothesis or question.

This research aims to answer the following two questions. How do library service catchment areas differ along lines of race, class, gender, etc. How do the public services in these catchment areas reflect the nature of their local constituents? 


# Materials and procedure

## Computational environment

```{r environment-setup, include = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c( 
  "tidycensus", "tidyverse", "sf", "classInt", "readr", "tigris",
  "rgdal","rstudioapi", "here", "s2", "pastecs", "tmap", "knitr", 
  "kableExtra", "broom", "leaflet", "usethis", "deldir", "spatstat"
)

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2023-06-26"
set.groundhog.folder("../../data/scratch/groundhog/")

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Run code, show outputs (don't show code)
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)

#set up Github repository as the R project
#use_github("azalecki/Zalecki-2023")

```

## Data and variables

Describe the **data sources** and **variables** to be used.
Data sources may include plans for observing and recording **primary data** or descriptions of **secondary data**.
For secondary data sources with numerous variables, the analysis plan authors may focus on documenting only the variables intended for use in the study.

Primary data sources for the study are to include ... .
Secondary data sources for the study are to include ... .

Each of the next subsections describes one data source.


### Chicago Boundary 
```{r chicago-bounds}
# Load in all places defined by the US Census 
il_places <- places(state = "IL")

il_places 

# Filter out Chicago from Census Places
chi <- il_places %>%
  dplyr::filter(NAME == 'Chicago')%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Plot geometry and check geometry/data type
plot(chi$geometry)
st_geometry_type(chi)
class(chi)

```

### American Community Survey Data

```{r acs-data, install = TRUE}

#Load in Census API Key. To get your own key visit this website: 

census_api_key("058bab25964a0d33dc97ba789df8df55ba443855")

# Query Sociol & Demographic data with Census tract boundaries

 # Age and Sex Table 

 # as_acs <- get_acs(
 #   geography = "tract",
 #   table = "S0101",
 #   county = "Cook",
 #   state = "IL",
 #   year = 2021,
 #   output = "wide",
 #   cache_table = TRUE,
 #   geometry = TRUE,
 #   keep_geo_vars = TRUE)%>%
 #   st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))


 # Race
 
 # Educational Attainment Table 

 edu_acs <- get_acs(
   geography = "tract",
   table = "B15003",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
   st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

 # School Enrollment 
 
 enr_acs <- get_acs(
   geography = "tract",
   table = "B14001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
   st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
 
# Employment table 

 emp_acs <- get_acs(
   geography = "tract",
   table = "B23025",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
   st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
 
# Nativity table 
 
 nat_acs <- get_acs(
   geography = "tract",
   table = "B05012",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
 
# Language Spoken at Home
 
 # lang_acs <- get_acs(
 #   geography = "tract",
 #   table = "B16002",
 #   county = "Cook",
 #   state = "IL",
 #   year = 2021,
 #   output = "wide",
 #   cache_table = TRUE,
 #   geometry = TRUE,
 #   keep_geo_vars = TRUE)%>%
 #  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
 
# Computers at Home
 
 # comp_acs <- get_acs(
 #   geography = "tract",
 #   table = "B28010",
 #   county = "Cook",
 #   state = "IL",
 #   year = 2021,
 #   output = "wide",
 #   cache_table = TRUE,
 #   geometry = TRUE,
 #   keep_geo_vars = TRUE)%>%
 #   st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
 
 # Household Income  
inc_acs <- get_acs(
   geography = "tract",
   table = "B19001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Check attributes of table

# Save query results

saveRDS(emp_acs, here("data", "raw", "public", "emp_acs.RDS"))
saveRDS(enr_acs, here("data", "raw", "public", "emp_acs.RDS"))
saveRDS(inc_acs, here("data", "raw", "public", "emp_acs.RDS"))
saveRDS(nat_acs, here("data", "raw", "public", "nat_acs.RDS"))

# Plot one of the tables on the map to test that tracts show up 

#leaflet() %>% 
  #addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
  #addPolygons(data = fc_acs, color = "blue", weight = 1, fillColor= "white", fillOpacity = 0.2)

```

```{r load-acs}

in_acs <- readRDS(here("data", "raw", "public", "inc_acs.RDS"))
emp_acs <- readRDS(here("data", "raw", "public", "emp_acs.RDS"))
nat_acs <- readRDS(here("data", "raw", "public", "nat_acs.RDS"))
enr_acs <- readRDS(here("data", "raw", "public", "enr_acs.RDS"))
```

### Libraries

```{r cpl-data}

#Load Chicago Public Library addresses from CSV file found in Folder: data/raw/public/CPL-Locations.csv

cpl_data = read_csv("https://raw.githubusercontent.com/azalecki/Zalecki-2023/main/data/raw/public/CPL-Locations.csv")

# Create points layer using Longitude and Latitude columns and set projection to UTM Zone 16, EPSG: 32616

points <- cpl_data %>%
  st_as_sf(coords = c("Longitude", "Latitude")) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Check class and geometry type of data 

class(points)
st_geometry_type(points)

# Plot points on map with Chicago boundary 

cpl_points_m <- leaflet() %>% 
                   addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
                   addPolygons(data = chi, color = "gray", weight = 1, fillColor= "white", fillOpacity = 0.2)%>%
                   addCircles(data = points, weight = 3, opacity= 1, color = "orange") 
cpl_points_m

```

### Census Block Data 

```{r pop-blocks}

# Query block geographic data from the 2020 Census population

blocks <- get_decennial(
  geography = "block",
  table = "P1",
  county = "Cook",
  state = "IL",
  year = 2020,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Plot block data on the map 

blocks_m <- leaflet() %>% 
              addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
              addPolygons(data = blocks, color = "blue", weight = 1, fillColor= "white", fillOpacity = 0.2)

blocks_m

```

## Prior observations  

Prior experience with the study area, prior data collection, or prior observation of the data can compromise the validity of a study, e.g. through p-hacking.
Therefore, disclose any prior experience or observations at the time of study pre-registration here, with example text below:

At the time of this study pre-registration, the authors had _____ prior knowledge of the geography of the study region with regards to the ____ phenomena to be studied.
This study is related to ____ prior studies by the authors

For each primary data source, declare the extent to which authors had already engaged with the data:

- [ ] no data collection has started
- [ ] pilot test data has been collected
- [ ] data collection is in progress and data has not been observed
- [ ] data collection is in progress and __% of data has been observed
- [ ] data collection is complete and data has been observed. Explain how authors have already manipulated / explored the data.

For each secondary source, declare the extent to which authors had already engaged with the data:

- [ ] data is not available yet
- [ ] data is available, but only metadata has been observed
- [ ] metadata and descriptive statistics have been observed
- [ ] metadata and a pilot test subset or sample of the full dataset have been observed
- [ ] the full dataset has been observed. Explain how authors have already manipulated / explored the data.

If pilot test data has been collected or acquired, describe how the researchers observed and analyzed the pilot test, and the extent to which the pilot test influenced the research design.

## Bias and threats to validity

Given the research design and the secondary data to be used, discuss common threats to validity and the approach to mitigating those threats, with an emphasis on geographic threats to validity.

These include:
  - uneven primary data collection due to geographic inaccessibility or other constraints
  - multiple hypothesis testing
  - edge or boundary effects
  - the modifiable areal unit problem
  - nonstationarity
  - spatial dependence or autocorrelation
  - temporal dependence or autocorrelation
  - spatial scale dependency
  - spatial anisotropies
  - confusion of spatial and a-spatial causation
  - ecological fallacy
  - uncertainty e.g. from spatial disaggregation, anonymization, differential privacy

## Data transformations

Describe all data transformations planned to prepare data sources for analysis.
This section should explain with the fullest detail possible how to transform data from the **raw** state at the time of acquisition or observation, to the pre-processed **derived** state ready for the main analysis.
Including steps to check and mitigate sources of **bias** and **threats to validity**.
The method may anticipate **contingencies**, e.g. tests for normality and alternative decisions to make based on the results of the test.
More specifically, all the **geographic** and **variable** transformations required to prepare input data as described in the data and variables section above to match the study's spatio-temporal characteristics as described in the study metadata and study design sections.
Visual workflow diagrams may help communicate the methodology in this section.

Examples of **geographic** transformations include coordinate system transformations, aggregation, disaggregation, spatial interpolation, distance calculations, zonal statistics, etc.

Examples of **variable** transformations include standardization, normalization, constructed variables, imputation, classification, etc.

Be sure to include any steps planned to **exclude** observations with *missing* or *outlier* data, to **group** observations by *attribute* or *geographic* criteria, or to **impute** missing data or apply spatial or temporal **interpolation**.

### ACS data transformations

The ACS classifies the data it collects in its own way but I wanted to reclassify it into bins to serve my purposes. I created bins/ simpler classifications for the ACS data.
Here is a table of the new source fields I created, what I named them and what ACS data columns make up these source fields. 

[INSERT TABLE HERE]
```{r new-bins}

# Make new bins for School Enrollment by level of school 
# se1: highschool or under | se2: undergraduate or graduate or professional school | se3: not enrolled in school 

enr_acs$se1 <- c(enr_acs$B14001_003E + 
                   enr_acs$B14001_004E + 
                   enr_acs$B14001_005E + 
                   enr_acs$B14001_006E + 
                   enr_acs$B14001_006E)

enr_acs$se2 <- c(enr_acs$B14001_008E + enr_acs$B14001_009E)

enr_acs$se3 <- c(enr_acs$B14001_010E)

# Make new columns for Employment status 
# emp1 : civilian labor employed | emp0: civilian labor unemployed 

emp_acs$emp0 <- c(emp_acs$B23025_007E)
emp_acs$emp1 <- c(emp_acs$B23025_002E)

# Rename columns for Nativity data. I don't need to add anything up here. 

# Make new columns for Household Income 
# hhi1: under 25k | hhi2: 25k - 49.9k | hhi3: 50k - 74.9k | hhi4: 75k - 99.9k | hhi5: 100k - 149.9k | hhi6: 150k - 199.9k | hhi7: over 200k

inc_acs$hhi1 <- c(inc_acs$B19001_002E + 
                    inc_acs$B19001_003E + 
                    inc_acs$B19001_004E + 
                    inc_acs$B19001_005E)

inc_acs$hhi2 <- c(inc_acs$B19001_006E + 
                    inc_acs$B19001_007E + 
                    inc_acs$B19001_008E + 
                    inc_acs$B19001_009E + 
                    inc_acs$B19001_010E)

inc_acs$hhi3 <- c(inc_acs$B19001_011E +
                    inc_acs$B19001_012E)
inc_acs$hhi4 <- c(inc_acs$B19001_013E)

inc_acs$hhi5 <- c(inc_acs$B19001_014E + 
                    inc_acs$B19001_015E)

inc_acs$hhi6 <- c(inc_acs$B19001_016E)
inc_acs$hhi7 <- c(inc_acs$B19001_017E) 

# Make new columns for Nativity status
# for0: native born | for1: foreign born 

nat_acs$for0 <- c(nat_acs$B05012_002E)
nat_acs$for1 <- c(nat_acs$B05012_003E)

# Make new columns for Educational Attainment 
# et1: no highschool diploma | et2: highschool diploma, equivalent, or some college  | et3: associates or bachelor's | et4: graduate or professional school 

edu_acs$et1 <- c(edu_acs$B15003_002E + 
                   edu_acs$B15003_003E + 
                   edu_acs$B15003_004E + 
                   edu_acs$B15003_005E + 
                   edu_acs$B15003_006E + 
                   edu_acs$B15003_007E + 
                   edu_acs$B15003_008E + 
                   edu_acs$B15003_009E + 
                   edu_acs$B15003_010E + 
                   edu_acs$B15003_011E + 
                   edu_acs$B15003_012E + 
                   edu_acs$B15003_013E + 
                   edu_acs$B15003_014E + 
                   edu_acs$B15003_015E + 
                   edu_acs$B15003_016E)

edu_acs$et2 <- c(edu_acs$B15003_017E + 
                   edu_acs$B15003_018E + 
                   edu_acs$B15003_019E + 
                   edu_acs$B15003_020E)

edu_acs$et3 <- c(edu_acs$B15003_021E + 
                   edu_acs$B15003_022E)

# edu_acs$et4 <- c(edu_acs$B15003_023E + 
#                    edu_acs$B15003_024E + 
#                    edu_acs$B15003_0025E)

```

I took one of the ACS tables and selected for the necessary geographic identifiers (STATEFP, COUNTYFP, TRACTCE, GEOID, NAME.X, ALAND, AWATER, geometry) and the source fields I had created in the last step. For all of the following tables I just selected for the source fields I had created because I will be doing a spatial join and selecting for the geographic fields would be redundant. 

```{r acs-filter}
# filter acs data by the columns that you want to keep in the new aggregate table

tabletest <- inc_acs %>%
  dplyr::select(STATEFP, COUNTYFP, TRACTCE,GEOID, NAME.x, ALAND, AWATER, geometry, hhi1, hhi2, hhi3, hhi4, hhi5, hhi6, hhi7)

tabletest2 <- emp_acs %>%
  dplyr::select(emp0, emp1)

# st_join to join tables 

tabletest3 <- st_join(tabletest, tabletest2)

```

I clipped the final table by the Chicago geometry as to only include tracts that are within Chicago's city boundaries.  
```{r tracts-clip-chi}

chi_tracts <- st_intersection(tabletest3, chi)%>%
  st_collection_extract("POLYGON")

#class(chi_tracts)

chi_tracts_m <- leaflet() %>% 
                  addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
                  addPolygons(data = chi_tracts, color = "blue", weight = 1, fillColor= "white", fillOpacity = 0.2)

chi_tracts_m
```

### Library Catchment Areas
To create the catchment areas I will create Thiessen/Voronoi polygons from the library points. 

```{r voronoi-polygons}

# Generate Thiessen/Voronoi polygons from library points
vor1 <- st_union(points)%>%
  st_voronoi()%>%
  st_collection_extract("POLYGON")

vorpoly = vor1 %>%
st_sf %>%
st_cast
#Plot polygons to make sure they loaded

plot(vorpoly)
class(vorpoly)

# Rejoin attributes from library points data to voronoi polygons 
# Because I had to union the points prior to st_voronoi() function the library attributes were lost 

vorpoly2 <- st_join(vorpoly, points)

# Clip voronoi polygons by Chicago boundary 
vor_chi <- st_intersection(vorpoly2, chi)
    
# Plot polygons to make sure they clipped

plot(vor_chi)

voronoi_m <- leaflet() %>% 
               addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
               addPolygons(data = vor_chi, color = "#7146BD", weight = 1, fillColor= "#E7E0F4", fillOpacity = 0.2)%>%
               addCircles(data = points, weight = 3, opacity= 1, color = "orange") 

voronoi_m

```

### Filter Population Blocks

```{r filter-blocks}

# Filter out blocks with no population data 
blocks_pop <- blocks %>%
  dplyr::filter(POP20 > 0)

# Clip blocks by Chicago Boundary and simpligy table by selecting for columns that I will need 

chi_pop <- st_as_sf(st_intersection(blocks_pop, chi)%>%
  select(TRACTCE20, BLOCKCE20, GEOID, ALAND20, AWATER20, HOUSING20, POP20, geometry))%>%
  st_collection_extract("POLYGON")

#st_geometry_type(chi_pop)
#plot(chi_pop$POP20)
```

```{r map-chi-blocks}

pal <- colorNumeric(
  palette = c("#F5FDF1", "#0D5B1E"),
  domain = chi_pop$POP20)


#binpal <- colorBin(c("#F5FDF1", "#0D5B1E"), chi_pop$POP20, 500, pretty = FALSE)

qpal <- colorQuantile(c("#F5FDF1", "#0D5B1E"), chi_pop$POP20, n = 10)

chi_pop_m <- leaflet() %>% 
              addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
              addPolygons(data = chi_pop, stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,color = ~qpal(POP20))%>%
              addPolygons(data = vor_chi, color = "#7146BD", weight = 1, fillColor= "#E7E0F4", fillOpacity = 0.2)

chi_pop_m
```
### Join Population Data and Population Weighted Re-Aggregation 
```{r centroids}

# Generate centroids for the blocks

centroids <- st_centroid(chi_pop)

# Check geometry type
#st_geometry_type(centroids)

# Plot the centroids on the map

centroids_m <- leaflet() %>% 
                addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
                addPolygons(data = chi_tracts, color = "gray", weight = 1, fillColor= "white", fillOpacity = 0.2)%>%
                addCircles(data = centroids, weight = 3, opacity= 1, color = "orange")

centroids_m
```

```{r pop-agg-prep-1}

# Join block centroids to tracts 

tracts_pop <- st_join(chi_tracts, centroids)

#Summarize population by tract 

group_tract <- tracts_pop %>%
                group_by(TRACTCE) %>%
                summarise(sum_pop = sum(POP20))

# Map!

qpal2 <- colorQuantile(c("#F5FDF1", "#0D5B1E"), group_tract$sum_pop, n = 10)

group_tract_m <- leaflet() %>% 
              addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
              addPolygons(data = group_tract, stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,color = ~qpal2(sum_pop))
              

group_tract_m


```

```{r pop-agg-prep-2}

# Intersect tracts with Voronoi polygons 

vorclip_tracts <- st_intersection(tracts_pop, vor_chi)%>%
  st_collection_extract("POLYGON")

# Join block centroids to new intersection polygons 

intersect_pop <- st_join(vorclip_tracts, centroids)

# Summarize population by intersected tracts 

int_grp_tract <- intersect_pop %>%
                group_by(TRACTCE) %>%
                summarise(sum_pop2 = sum(POP20))

# Map!
qpal3 <- colorQuantile(c("#F5FDF1", "#0D5B1E"), int_grp_tract$sum_pop2, n = 10)

int_grp_tract_m <- leaflet() %>% 
              addProviderTiles(providers$Esri.WorldGrayCanvas) %>% 
              addPolygons(data = int_grp_tract, stroke = FALSE, smoothFactor = 0.2, fillOpacity = 1,color = ~qpal3(sum_pop2))
              

int_grp_tract_m

```

```{r pop-agg-calc}

# Population Weighted Re-Aggregation 
 
# Calculate population weight ratio (PWR) | fragment population / source population = population weight ratio

output <- mutate(input_data,propPop = secPOP20 / POP20)

# Multiply source fields by the PWR to estimate the population weighted value  

output <- mutate(final_table,
          hhi1_w = hhi1 * pwr,
          hhi2_w = hhi2 * pwr,
          hhi3_w = hhi3 * pwr,
          hhi4_w = hhi4 * pwr,
          hhi5_w = hhi5 * pwr,
          hhi6_w = hhi6 * pwr,
          hhi7_w = hhi7 * pwr,
          emp0_w = emp0 * pwr, 
          emp1_w = emp1 * pwr, 
          for0_w = for0 * pwr, 
          for1_w = for1 * pwr,
          se1_w = se1 * pwr, 
          se2_w = se2 * pwr, 
          se3_w = se3 * pwr)


```

## Analysis

Describe the methods of analysis that will directly test the hypotheses or provide results to answer the research questions.
This section should explicitly define any spatial / statistical *models* and their *parameters*, including *grouping* criteria, *weighting* criteria, and *significance thresholds*.
Also explain any follow-up analyses or validations.

# Results



# Discussion

Describe how the results are to be interpreted *vis a vis* each hypothesis or research question.

# Integrity Statement

The authors of this preregistration state that they completed this preregistration to the best of their knowledge and that no other preregistration exists pertaining to the same hypotheses and research.


This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)

# References
