---
title: "Who is the public in public libraries? Exploring the spatial variations of the changing dynamics of library services in Chicago, IL"
author: "Alexandra Ola Zalecki"
date: "`r Sys.Date()`"
output: html_document
editor_options:
  markdown:
    wrap: sentence
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding, output_dir = "../../docs/report") })
---

# Abstract

Rising inequality and increased privatization of space in urban landscapes is bringing attention to some of the only public spaces left: libraries. This study analyzes to what extent library service areas differ along lines of inequality like race, class, etc. This study will delineate library catchment areas in Chicago, IL and compare them with socio-economic data at the tract and block level. This analysis is the first part of a two pronged methods that aims to answer the question of to what extent the catchment areas are distinct. 

## Study Metadata

- `Key words`: public space, libraries, population weighted aggregation, service areas 
- `Subject`: Social and Behavioral Sciences: Geography: Human Geography
- `Date created`: 11/28/2023
- `Date modified`: 1/28/2024
- `Spatial Coverage`: Chicago, IL
- `Spatial Resolution`: Census Tracts, Census Blocks, Library Service Areas
- `Spatial Reference System`: EPSG:32616 
- `Temporal Coverage`: 2017-Present
- `Temporal Resolution`: Specify the temporal resolution of your study---i.e. the duration of time for which each observation represents or the revisit period for repeated observations

# Study design

This study is a reproduction of my own **an original study**. As part of my independent research work with Professor Peter Nelson, I created a workflow in QGIS to answer the question: How do library service catchment areas differ along lines of race, class, gender, etc? In order to streamline this research and make it reproducible/replicable I decided to reproduce the workflow in R and create a research compendium for it as part of my final independent project in GEOG0361: Open GIScience.

This research aims to answer the following two questions. How do library service catchment areas differ along lines of race, class, gender, etc. How do the public services in these catchment areas reflect the nature of their local constituents? 

# Materials and procedure

## Computational environment

```{r environment-setup, warning = FALSE}
# record all the packages you are using here
# this includes any calls to library(), require(),
# and double colons such as here::i_am()
packages <- c( 
  "tidycensus", "tidyverse", "sf", "classInt", "readr", "tigris",
  "rgdal","rstudioapi", "here", "s2", "pastecs", "tmap", "knitr", 
  "kableExtra", "broom", "usethis", "deldir", "spatstat", "webshot", "rstatix", "RColorBrewer"
)

# force all conflicts to become errors
# if you load dplyr and use filter(), R has to guess whether you mean dplyr::filter() or stats::filter()
# the conflicted package forces you to be explicit about this
# disable at your own peril
# https://conflicted.r-lib.org/
require(conflicted)

# load and install required packages
# https://groundhogr.com/
if (!require(groundhog)) {
  install.packages("groundhog")
  require(groundhog)
}

if(!require(here)){
  install.packages("here")
  require(here)
}

# this date will be used to determine the versions of R and your packages
# it is best practice to keep R and its packages up to date
groundhog.day <- "2023-06-26"
set.groundhog.folder("../../data/scratch/groundhog/")

# this replaces any library() or require() calls
groundhog.library(packages, groundhog.day)
# you may need to install a correct version of R
# you may need to respond OK in the console to permit groundhog to install packages
# you may need to restart R and rerun this code to load installed packages
# In RStudio, restart r with Session -> Restart Session

# record the R processing environment
# alternatively, use devtools::session_info() for better results
writeLines(
  capture.output(sessionInfo()),
  here("procedure", "environment", paste0("r-environment-", Sys.Date(), ".txt"))
)

# save package citations
knitr::write_bib(c(packages, "base"), file = here("software.bib"))

# set up default knitr parameters
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(
  echo = FALSE, # Run code, show outputs (don't show code)
  fig.retina = 4,
  fig.width = 8,
  fig.path = paste0(here("results", "figures"), "/")
)

#Switch the graphics output from raster to vector
knitr::opts_chunk$set(dev="png")

```
## Data and variables

Each of the next subsections describes one data source.
Primary data sources are to include the following. 

```{r load-website-data}
# Load website survey data from the Github data folder 

web = read_csv("https://raw.githubusercontent.com/azalecki/Zalecki-2023/main/data/raw/public/WS_1_29_24.csv")
```

Secondary data sources for the study are to include the following. 

### Chicago Shapefile 

```{r download-places, eval= FALSE}

# Load in all places defined by the US Census
il_places <- places(state = "IL")

# Save data 
saveRDS(il_places, here("data", "raw", "public", "il_places.RDS"))

```

```{r load-clip-places}
# Load Census places for Illinois
il_places <- readRDS(here("data", "raw", "public", "il_places.RDS"))

```
 
 
# Download block data from the 2020 Census for Cook County, IL  
Because, the ACS data tables do not come with population data I have to bring in population data separately. Population data for this study is referenced at the block level for the whole of Cook County, IL. The year that the data is derived from is 2020.

```{r blocks-table}
cook_blocks_tbl <-get_decennial(geography="block", state="IL", county="Cook", year=2020,
                         variables=c(block_pop="P1_001N", block_hu="H1_001N")) %>% 
  pivot_wider(id_cols = "GEOID", names_from = variable, values_from = value)

saveRDS(cook_blocks_tbl, here("data", "raw", "public", "cook_blocks_tbl.RDS"))

```
  
```{r blocks-shape, eval= FALSE}

cook_blocks_shp <- get_decennial(
  geography = "block",
  table = "P1",
  county = "Cook",
  state = "IL",
  year = 2020,
  output = "wide",
  cache_table = TRUE,
  geometry = TRUE,
  keep_geo_vars = TRUE) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

saveRDS(cook_blocks_shp, here("data", "raw", "public", "cook_blocks_shp.RDS"))

```

```{r load-blocks}

#Load block data 
cook_blocks_tbl <- readRDS(here("data", "raw", "public", "cook_blocks_tbl.RDS"))
cook_blocks_shp <- readRDS(here("data", "raw", "public", "cook_blocks_shp.RDS"))
                  
```

# Download tract data from the 2021 American Community Survey(ACS) 
```{r download-tract-table}
cook_tracts_tbl <-get_decennial(geography="tract", state="IL", county="Cook", year=2020,
                         variables=c(tract_pop="P1_001N", tract_hu="H1_001N")) %>% 
  pivot_wider(id_cols = "GEOID", names_from = variable, values_from = value) %>% 
  arrange(GEOID)

saveRDS(cook_tracts_tbl, here("data", "raw", "public", "cook_tracts_tbl.RDS"))
```

```{r download-tracts-shp, eval= FALSE}

cook_tracts_shp <- tracts(
                state = "IL",
                county = "Cook",
                cb = FALSE,
                resolution = "500k",
                year = 2020)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

saveRDS(cook_tracts_shp, here("data", "raw", "public", "cook_tracts_shp.RDS"))

```

```{r load-tracts}

#Load tract data 
cook_tracts_tbl <- readRDS(here("data", "raw", "public", "cook_tracts_tbl.RDS"))
cook_tracts_shp <- readRDS(here("data", "raw", "public", "cook_tracts_shp.RDS"))
                  
```
### Download social-demographic data from the 2021 American Community Survey(ACS) 

I will add a more comprehensive list of variables as my senior research project progresses.

```{r api-key, install = TRUE}
# Load in Census API Key. To get your own key visit this website: 

census_api_key("058bab25964a0d33dc97ba789df8df55ba443855")
```

```{r query-acs-data, eval = FALSE}

# Query Social & Demographic data tables with Census tract boundaries

 # Age and Sex Table 

  as_acs <- get_acs(geography = "tract",table = "B01001",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()

 # Race & Ethnicity Table
 
  race_acs <- get_acs(
    geography = "tract",
    table = "B03002",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Household Type 
  
  hhold_acs <- get_acs(
    geography = "tract",
    table = "B11003",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Educational Attainment Table 

  edu_acs <- get_acs(
    geography = "tract",
    table = "B15003",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
  
  # Disability Status Table 
  
  dis_acs <- get_acs(
    geography = "tract",
    table = "B18101",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()

  # School Enrollment 
 
  enr_acs <- get_acs(
    geography = "tract",
    table = "B14001",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Employment Table 

  emp_acs <- get_acs(
    geography = "tract",
    table = "B23025",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Nativity Table 
 
  nat_acs <- get_acs(
    geography = "tract",
    table = "B05012",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
    st_drop_geometry()
 
# Language Spoken at Home

   lang_acs <- get_acs(
     geography = "tract",
     table = "B06007",
     county = "Cook",
     state = "IL",
     year = 2016,
     output = "wide",
     cache_table = TRUE,
     geometry = TRUE,
     keep_geo_vars = TRUE)%>%
     st_drop_geometry()
 
# Computers at Home
 
  comp_acs <- get_acs(
    geography = "tract",
    table = "B28010",
    county = "Cook",
    state = "IL",
    year = 2021,
    output = "wide",
    cache_table = TRUE,
    geometry = TRUE,
    keep_geo_vars = TRUE)%>%
     st_drop_geometry()
 
 # Household Income Table 
inc_acs <- get_acs(
   geography = "tract",
   table = "B19001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
    st_drop_geometry()

# Poverty Status 
pov_acs <- get_acs(
   geography = "tract",
   table = "B17001",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE)%>%
    st_drop_geometry()

#Median Family Income
m_inc_acs <- get_acs(
   geography = "tract",
   table = "B19013",
   county = "Cook",
   state = "IL",
   year = 2021,
   output = "wide",
   cache_table = TRUE,
   geometry = TRUE,
   keep_geo_vars = TRUE) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Save query results

saveRDS(edu_acs, here("data", "raw", "public", "edu_acs.RDS"))
saveRDS(as_acs, here("data", "raw", "public", "as_acs.RDS"))
saveRDS(race_acs, here("data", "raw", "public", "race_acs.RDS"))
saveRDS(hhold_acs, here("data", "raw", "public", "hhold_acs.RDS"))
saveRDS(dis_acs, here("data", "raw", "public", "dis_acs.RDS"))
saveRDS(enr_acs, here("data", "raw", "public", "enr_acs.RDS"))
saveRDS(emp_acs, here("data", "raw", "public", "emp_acs.RDS"))
saveRDS(nat_acs, here("data", "raw", "public", "nat_acs.RDS"))
saveRDS(lang_acs, here("data", "raw", "public", "lang_acs.RDS"))
saveRDS(comp_acs, here("data", "raw", "public", "comp_acs.RDS"))
saveRDS(inc_acs, here("data", "raw", "public", "inc_acs.RDS"))
saveRDS(pov_acs, here("data", "raw", "public", "pov_acs.RDS"))
saveRDS(m_inc_acs, here("data", "raw", "public", "m_inc_acs.RDS"))


```

```{r load-queried-acs-data}

#Load ACS Data 

edu_acs <- readRDS(here("data", "raw", "public", "edu_acs.RDS"))
as_acs <- readRDS(here("data", "raw", "public", "as_acs.RDS"))
race_acs <- readRDS(here("data", "raw", "public", "race_acs.RDS"))
hhold_acs <- readRDS(here("data", "raw", "public", "hhold_acs.RDS"))
dis_acs <- readRDS(here("data", "raw", "public", "dis_acs.RDS"))
enr_acs <- readRDS(here("data", "raw", "public", "enr_acs.RDS"))
emp_acs <- readRDS(here("data", "raw", "public", "emp_acs.RDS"))
nat_acs <- readRDS(here("data", "raw", "public", "nat_acs.RDS"))
lang_acs <- readRDS(here("data", "raw", "public", "lang_acs.RDS"))
comp_acs <- readRDS(here("data", "raw", "public", "comp_acs.RDS"))
inc_acs <- readRDS(here("data", "raw", "public", "inc_acs.RDS"))
m_inc_acs <- readRDS(here("data", "raw", "public", "m_inc_acs.RDS"))
pov_acs <- readRDS(here("data", "raw", "public", "pov_acs.RDS"))

```

### Public Library Locations

Data for Chicago Public Library locations comes in CSV format with coordinate data. Prior to uploading the CSV file into the Github site I used Microsoft Excel to manually separate the Longitude and Latitude values into two separate columns. No other data manipulation was done in Excel. 

```{r cpl-data, warning = FALSE}

#Load Chicago Public Library addresses from CSV file found in Folder: data/raw/public/CPL-Locations.csv

cpl_data = read_csv("https://raw.githubusercontent.com/azalecki/Zalecki-2023/main/data/raw/public/CPL-Locations.csv") %>% tibble()

# Create points layer using Longitude and Latitude columns and set projection to UTM Zone 16, EPSG: 32616

points <- cpl_data %>%
  st_as_sf(coords = c("Longitude", "Latitude")) %>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))


```

## Bias and threats to validity

**Edge/shape effects when creating polygons to represent library service/catchment areas**

Visualizing catchment areas for libraries is my first objective because, unlike primary schools that have definite attendance boundaries, libraries do not have proper "service areas." In the past, Thiessen/Voronoi polygons have been used to map catchment or service areas by proximity to points. As explained by Flitter et al(nd), GIS tools that generate Thiessen polygons draw shapes around a layer of point data where every location within one shape is nearer to its center point than all other points in the layer. These proximal regions assume that people are more likely to visit the library closest to them and as a result library services should reflect their local constituents. I recognize that this method has its flaws because this is not always the case. Some people may frequent libraries outside of their residential neighborhood for a variety of reasons and there is no way of accurately tracking that. The other option would be to draw buffers around library points like in the method we saw in the Kang et al. (year) study or calculate a network analysis. Thiessen polygons are, however, the simpler and computationally less intense option to a full-on network analysis. Although they might seem arbitrary I have attempted to improve the validity by including a population-weighted aggregation to more accurately estimate the neighborhood characteristics of the library service areas.

## Data transformations

```{r clip-places}

# Filter out Chicago from Census Places

chi <- il_places %>%
  dplyr::filter(NAME == 'Chicago')%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# Plot geometry

plot(chi$geometry)
```

### Block transformations
### Filter Population Blocks

Because I will be doing a population weighted aggregation I have to prepare the population data to some extent. I started by filtering out the blocks with no population data. The table of blocks that have population data was then clipped by the Chicago boundary. Then I selected for the columns that I wanted to keep working with to simplify the data table. The columns I selected for include: TRACTCE20, BLOCKCE20, GEOID, ALAND20, AWATER20, HOUSING20, POP20, geometry. 

```{r filter-blocks, warning = FALSE}

# Clip blocks shape by Chicago Boundary and simplify table by selecting for columns that I will need 

chi_blocks_shp <- st_intersection(cook_blocks_shp, chi)%>%
  st_collection_extract("POLYGON")%>%
             select(GEOID,geometry)

chi_blocks_list<-chi_blocks_shp %>% 
  select(GEOID) %>% 
  as.tibble()


class(chi_blocks_shp)
plot(chi_blocks_shp$geometry)

# Clip tracts shape by Chicago Boundary and simplify table by selecting for columns that I will need 
chi_tracts_shp <-  st_intersection(cook_tracts_shp, chi)%>%
  st_collection_extract("POLYGON")%>%
             select(GEOID,geometry)

chi_tracts_list<-chi_tracts_shp %>% 
  select(GEOID) %>% 
  as.tibble()


class(chi_tracts_shp)
plot(chi_tracts_shp$geometry)
```


### Library Catchment Areas

To create the catchment areas I will create Thiessen/Voronoi polygons. This was done by using the st_voronoi() function on the library points data. Finally, I clipped the voronoi diagram by the Chicago shapefile. 

```{r voronoi-polygons, warning = FALSE}

# Generate Thiessen/Voronoi polygons from library points

vorpoly <- st_union(points)%>%
  st_voronoi()%>%
  st_collection_extract("POLYGON")%>%
  st_sf %>%
  st_cast

# Rejoin attributes from library points data to voronoi polygons 
# Because I had to union the points prior to st_voronoi() function the library attributes were lost 
vorjoin <- st_join(vorpoly, points)

# Clip voronoi polygons by Chicago boundary 
chi_vor <- st_intersection(vorjoin, chi)%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))
    
# Plot polygons on a map with librayr points

vor_map <- tmap_mode("plot")
           tm_shape(chi_vor)+
              tm_borders(col="black" )+
           tm_shape(points) +
              tm_dots(size=0.05, col = "red")+ 
           tm_layout(legend.position = c("left", "bottom")) +
           tm_add_legend("symbol", col = "red", size = 0.5, labels = "Library Points")
           
vor_map

```

### ACS data transformations

The ACS classifies the data it collects in its own way but I wanted to reclassify it into different categories.

After creating the new classifications, I selected for the columns that I wanted to keep and work with. This included all of the necessary geographic identifiers(STATEFP, COUNTYFP, TRACTCE, GEOID, NAME.X, ALAND, AWATER, geometry) and the source fields I had created in the previous step. Finally, I clipped the table by the Chicago shapefile so to only include tracts that are within Chicago's city boundaries. 

```{r new-bins}

# Make new columns for Age categories 

as_acs$child <- c(as_acs$B01001_003E + 
                  as_acs$B01001_004E + 
                  as_acs$B01001_005E + 
                  as_acs$B01001_027E + 
                  as_acs$B01001_028E + 
                  as_acs$B01001_029E)

as_acs$teen <- c(as_acs$B01001_006E + 
                 as_acs$B01001_007E +
                 as_acs$B01001_030E +
                 as_acs$B01001_031E)

as_acs$yad <- c(as_acs$B01001_008E + 
                as_acs$B01001_009E + 
                as_acs$B01001_010E +
                as_acs$B01001_011E + 
                as_acs$B01001_032E + 
                as_acs$B01001_033E + 
                as_acs$B01001_034E + 
                as_acs$B01001_035E)

as_acs$mad <- c(as_acs$B01001_012E + 
                as_acs$B01001_013E +
                as_acs$B01001_014E + 
                as_acs$B01001_015E +
                as_acs$B01001_016E +
                as_acs$B01001_036E +
                as_acs$B01001_037E +
                as_acs$B01001_038E +
                as_acs$B01001_039E +
                as_acs$B01001_040E)

as_acs$sen <- c(as_acs$B01001_017E + 
                as_acs$B01001_018E + 
                as_acs$B01001_019E +
                as_acs$B01001_020E +
                as_acs$B01001_021E +
                as_acs$B01001_022E +
                as_acs$B01001_023E + 
                as_acs$B01001_024E +
                as_acs$B01001_025E +
                as_acs$B01001_041E +
                as_acs$B01001_042E +
                as_acs$B01001_043E +
                as_acs$B01001_044E +
                as_acs$B01001_045E +
                as_acs$B01001_046E +
                as_acs$B01001_047E +
                as_acs$B01001_048E +
                as_acs$B01001_049E)

as_acs$male <- c(as_acs$B01001_002E)
                 
as_acs$female <- c(as_acs$B01001_026E)






# Rename Race columns to make the names more intuitive 

race_acs$white <- c(race_acs$B03002_003E)
race_acs$black <- c(race_acs$B03002_004E)
race_acs$native <- c(race_acs$B03002_005E)
race_acs$asian <- c(race_acs$B03002_006E)
race_acs$hawpi <- c(race_acs$B03002_007E)
race_acs$other <- c(race_acs$B03002_008E)
race_acs$mixed <- c(race_acs$B03002_009E+ 
                      race_acs$B03002_010E + 
                      race_acs$B03002_011E)
race_acs$latinx <-c(race_acs$B03002_012E)

# Make new columns for Household Income 

inc_acs$hhi1 <- c(inc_acs$B19001_002E + 
                    inc_acs$B19001_003E + 
                    inc_acs$B19001_004E + 
                    inc_acs$B19001_005E)

inc_acs$hhi2 <- c(inc_acs$B19001_006E + 
                    inc_acs$B19001_007E + 
                    inc_acs$B19001_008E + 
                    inc_acs$B19001_009E + 
                    inc_acs$B19001_010E)

inc_acs$hhi3 <- c(inc_acs$B19001_011E +
                    inc_acs$B19001_012E)
inc_acs$hhi4 <- c(inc_acs$B19001_013E)

inc_acs$hhi5 <- c(inc_acs$B19001_014E + 
                    inc_acs$B19001_015E)

inc_acs$hhi6 <- c(inc_acs$B19001_016E)
inc_acs$hhi7 <- c(inc_acs$B19001_017E) 


# Make new columns for Employment status
# emp1 : civilian labor employed | emp0: civilian labor unemployed

 emp_acs$emp0 <- emp_acs$B23025_007E
 emp_acs$emp1 <- (emp_acs$B23025_002E)

# Rename columns for Nativity data. 
#Make new columns for Nativity status
#for0: native born | for1: foreign born

 nat_acs$for0 <- c(nat_acs$B05012_002E)
 nat_acs$for1 <- c(nat_acs$B05012_003E)

# Make new columns for Educational Attainment
# et1: no highschool diploma | et2: highschool diploma, equivalent, or some college  | et3: associates or bachelor's |et4: graduate or professional school

 edu_acs$et1 <- c(edu_acs$B15003_002E +
                    edu_acs$B15003_003E +
                    edu_acs$B15003_004E +
                    edu_acs$B15003_005E +
                    edu_acs$B15003_006E +
                    edu_acs$B15003_007E +
                    edu_acs$B15003_008E +
                    edu_acs$B15003_009E +
                    edu_acs$B15003_010E +
                    edu_acs$B15003_011E +
                    edu_acs$B15003_012E +
                    edu_acs$B15003_013E +
                    edu_acs$B15003_014E +
                    edu_acs$B15003_015E +
                    edu_acs$B15003_016E)

 edu_acs$et2 <- c(edu_acs$B15003_017E +
                    edu_acs$B15003_018E +
                    edu_acs$B15003_019E +
                    edu_acs$B15003_020E)

 edu_acs$et3 <- c(edu_acs$B15003_021E +
                    edu_acs$B15003_022E)

 edu_acs$et4 <- c(edu_acs$B15003_023E +
                    edu_acs$B15003_024E +
                    edu_acs$B15003_025E)
 

#Language spoken at home
 
lang_acs$eng <- lang_acs$B06007_002E
lang_acs$noneng <- c(lang_acs$B06007_003E+lang_acs$B06007_006E)

lang_acs$lang4 <- c(lang_acs$B06007_004E + 
                  lang_acs$B06007_007E)

lang_acs$lang5 <- c(lang_acs$B06007_005E + 
                  lang_acs$B06007_008E)

# Make new bins for School Enrollment by level of school
# se1: highschool or under | se2: undergraduate or graduate or professional school | se3: not enrolled in school

enr_acs$se1 <- c(enr_acs$B14001_003E +
                    enr_acs$B14001_004E +
                    enr_acs$B14001_005E +
                    enr_acs$B14001_006E +
                    enr_acs$B14001_006E)

enr_acs$se2 <- c(enr_acs$B14001_008E + enr_acs$B14001_009E)

enr_acs$se3 <- c(enr_acs$B14001_010E)

# Make new columns for Poverty Status Categories
pov_acs$povtotal <- c(pov_acs$B17001_002E)
```

```{r filter-acs}

# filter acs data by the columns that you want to keep in the new aggregate table

as_tab <- as_acs %>% 
  dplyr::select(GEOID,child, teen, yad, mad, sen, male, female)

hhi_tab <- inc_acs %>%
  dplyr::select(GEOID, hhi1, hhi2, hhi3, hhi4, hhi5, hhi6, hhi7)

emp_tab <- emp_acs %>% 
  dplyr::select(GEOID, emp0, emp1)

nat_tab <- nat_acs %>% 
  dplyr::select(GEOID, for0, for1)

edu_tab <- edu_acs %>% 
  dplyr::select(GEOID, et1, et2, et3, et4)

race_tab <- race_acs %>% 
  dplyr::select(GEOID, white, black, native, asian, hawpi, mixed, latinx)

m_inc_tab <- m_inc_acs %>%
  dplyr::select(GEOID, B19013_001E)

as_tab <- as_acs %>% 
  dplyr::select(GEOID, child, teen, yad, mad, sen)

lang_tab <-lang_acs %>%
  dplyr::select(GEOID, eng, noneng)

enr_tab <- enr_acs %>%
  dplyr::select(GEOID, se1, se2, se3)

pov_tab <- pov_acs %>% 
  dplyr::select(GEOID, povtotal)

# Join the ACS data to the tract table 

acs_table <- cook_tracts_tbl %>% inner_join(as_tab, by="GEOID")%>%
                                 inner_join(race_tab, by="GEOID") %>%
                                 inner_join(emp_tab, by="GEOID") %>% 
                                 inner_join(nat_tab, by="GEOID")%>% 
                                 inner_join(edu_tab, by="GEOID")%>%
                                 inner_join(lang_tab,by="GEOID")%>%
                                 inner_join(pov_tab, by="GEOID")%>%

  mutate(tract=substr(GEOID, 1, 11)) %>%  arrange(tract)


```

## Calculate Weights 
```{r weights}
# Calculate a  weighting factor that is the proportion of the census tract population in a every individual census block.This proportion is representative of the population contribution of an individual block towards the total population of the census tract that it belongs to.

weights_chi <- cook_blocks_tbl %>% 
  mutate(tract=substr(GEOID, 1, 11)) %>% 
  arrange(tract) %>% 
  merge(cook_tracts_tbl, by.x="tract", by.y="GEOID", all.x=T) %>% 
  mutate(block=substr(GEOID, 1, 16)) %>% 
  mutate(pop_wt=block_pop/tract_pop, hu_wt=block_hu/tract_hu)

```

```{r weights-mutate}
# Apply the proportional weight to the social demographic variables 

acs_table_wt <- weights_chi %>% merge(acs_table, by.x="tract", by.y="GEOID", all.x=T) %>% mutate(latinx_app=pop_wt*latinx)%>%
mutate(for_app=pop_wt*for1)%>%
mutate(bach_app=pop_wt*et3)%>%
mutate(unemp_app=pop_wt*emp0)%>%
mutate(black_app=pop_wt*black)%>%
mutate(white_app=pop_wt*white)%>%
mutate(lang_app=pop_wt*noneng)%>%
mutate(asian_app=pop_wt*asian)%>% 
mutate(povtot_app=pop_wt*povtotal)
# mutate(man_app=pop_wt*male)%>%
# mutate(fem_app= pop_wt*female)

```

```{r pop-weight-agg}

# Generate centroids for the blocks
centroids <- st_centroid(chi_blocks_shp)

# Join library names to centroids
vor_blocks <- st_join(chi_vor, centroids, join= st_intersects, left=TRUE)

# Join weights table to library service data
lib_service <- acs_table_wt %>% 
  merge(vor_blocks, by.x="GEOID", by.y="GEOID.y", all.x=T)

#Aggregate variable apportionments

agg_latinx <- aggregate(latinx_app ~ NAME, data = lib_service, sum)
agg_unemp <- aggregate(unemp_app ~ NAME, data= lib_service, sum)
agg_college <- aggregate(bach_app ~ NAME, data= lib_service, sum)
agg_foreign <- aggregate(for_app ~ NAME, data=lib_service, sum)
agg_white<- aggregate(white_app ~ NAME, data=lib_service, sum)
agg_black<-aggregate(black_app ~ NAME, data=lib_service, sum)
agg_asian<-aggregate(asian_app ~ NAME, data=lib_service, sum)
agg_pov <- aggregate(povtot_app ~ NAME, data=lib_service, sum)
# agg_fem <- aggregate(fem_app ~ NAME, data= lib_service, sum)
agg_noneng <- aggregate(lang_app ~ NAME, data= lib_service, sum)
agg_pop <- aggregate(block_pop ~ NAME, data= lib_service, sum)

#join back to catchment layer
catchment <- chi_vor %>% merge(agg_latinx, by="NAME")%>% 
  merge(agg_unemp, by="NAME") %>% 
  merge(agg_college, by="NAME")%>% 
  merge(agg_foreign, by="NAME")%>% 
  merge(agg_white, by="NAME")%>%
  merge(agg_noneng, by= "NAME")%>%
  merge(agg_pop, by= "NAME")%>%
  merge(agg_black, by='NAME')%>%
  merge(agg_asian, by='NAME')%>% 
  merge(agg_pov, by='NAME')

```

```{r normalize}

catchment.norm <-catchment %>% 

mutate(black_norm=black_app/block_pop, white_norm=white_app/block_pop, bach_norm=bach_app/block_pop, asian_norm=asian_app/block_pop, latinx_norm=latinx_app/block_pop, unemp_norm=unemp_app/block_pop, for_norm=for_app/block_pop, lang_norm=lang_app/block_pop, pov_norm=povtot_app/block_pop)

```


```{r map-catchment}
tmap_style("white")
tm_predictor <-tmap_mode("plot")

tm_shape(catchment.norm) +
  tm_polygons(col="unemp_norm", style="pretty",palette = brewer.pal(n = 5, name = "Oranges"), title="% Unemployed", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_predictor

```

```{r race-map}

acs_data <- left_join(chi_tracts_shp, acs_table)

race_pop <- mutate(acs_data, majRace = case_when(
  white > .60 ~ 'White',
  black > .60 ~ 'Black',
  asian > .60 ~ 'Asian',
  latinx > .60 ~ 'Latino',
  mixed > .60 ~ 'Mixed',
  TRUE ~ 'Other'))

tmap_mode("plot")
tm_shape(race_pop) +
  tm_polygons(col="majRace", title="Racial Majority", lwd= 0, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)

```
### join website data to voronoi shapefile 
```{r web_vor_shp}

web_vor <- left_join(chi_vor, web, by="NAME")%>%
  st_set_crs(st_crs("+proj=utm +zone=16 +datum=WGS84"))

# make tibble 

web.new <- web_vor %>%
  mutate(HHELP=factor(HHELP, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(CHBOOK=factor(CHBOOK, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(UMEDIA=factor(UMEDIA, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(MHSS=factor(MHSS, levels=c(0,1), labels=c( "No", "Yes"))) %>%
  mutate(CITCORNER=factor(CITCORNER, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(HSPOT=factor(HSPOT, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(CYBNAV=factor(CYBNAV, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(NE_MATER=factor(NE_MATER, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(IP_HHELP=factor(IP_HHELP, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(STROOMS=factor(STROOMS, levels=c(0,1), labels=c( "No", "Yes")))%>%
  mutate(COMP=factor(COMP, levels=c(0,1), labels=c( "No", "Yes")))
             
```

```{r join-pred-out-vars}

# Join tables with predictor and outcome variables together for the statistical analysis

grand_tbl <- inner_join(catchment, web, by="NAME") %>% 
  dplyr::select(NAME, latinx_app, unemp_app, bach_app, for_app, white_app, fem_app, lang_app, block_pop, CIRC, VIST, HSPOT, CHBOOK, HHELP, IP_HHELP, CITCORNER, CYBNAV, UMEDIA)%>% 
  st_drop_geometry()


```

# Results

```{r outliers}
web %>% identify_outliers(VIST)%>%
  print(width=Inf)

no_outliers_vist <- web %>% filter(web$VIST < 116554)
no_outliers_circ <- web %>% filter(web$CIRC < 142413)
no_outliers_comp <- web %>% filter(web$COMPSES < 23702)

boxplot(no_outliers_vist$VIST)
boxplot(no_outliers_circ$CIRC)
boxplot(no_outliers_comp$COMPSES)
```

```{r mapping-web}

tm_outcome <-tmap_mode("plot")
tm_shape(web.new) +
  tm_polygons("NE_MATER",palette = c("No" = "#44a5c2", "Yes" = "#ffae49"), title="Non-English Materials", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8) + 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_outcome

tm_outcome2 <- tmap_mode("plot")
tm_shape(web.new) +
  tm_polygons(col="COMPSES", palette = brewer.pal(n = 5, name = "Greens"), style="jenks", title="Computer Sessions", lwd= NA, border.col="lightgrey") +
  tm_layout(legend.width=3, legend.text.size = .6, legend.title.size = .8, asp=0.8)+ 
  tm_shape(catchment) + 
  tm_borders("white", lwd = .5)+ 
  tm_shape(chi)+ 
  tm_borders("darkgrey", lwd=.5)

tm_outcome2
```

``` {r rename}
colnames(web) <- c('NAME','Circulation','Visitation', 'Hotspot Lending', 'Chromebook Lending', 'Homework Help','InPerson Homework Help', 'OL_HHELP', 'WL_HHELP', 'Citizenship Corner', 'CyberNavigators', 'OL_CYBNAV', 'WL_CYBNAV', 'Study Rooms', 'N_STROOMS','Meeting Room', 'YouMedia', 'NonEnglish Materials', 'LANG1', 'LANG2', 'LANG3', 'Computers', 'Computer Sessions', 'Mental Health Services')
```

```{r stacked-bar}
# web%>%
#   select(NAME, NE_MATER,IP_HHELP, CYBNAV, CITCORNER, MHSS, HSPOT, CHBOOK, UMEDIA, MTROOMS, STROOMS)%>%
#   pivot_longer(!NAME, names_to="service", values_to="provides")%>%
#   mutate(provides=factor(provides, levels=c("0","1"), labels=c("No","Yes")))%>%
#   ggplot(aes(y=service, fill=provides))+
#   geom_bar(stat="count")

web %>% 
  select(NAME, `NonEnglish Materials`, `InPerson Homework Help`, CyberNavigators, `Citizenship Corner`, `Mental Health Services`, `Hotspot Lending`, `Chromebook Lending`, YouMedia, `Meeting Room`, `Study Rooms`)%>%
  pivot_longer(!Name, names_to="service", values_to="provides")%>%
  mutate(provides=factor(provides, levels=c("0","1"), labels=c("No","Yes")))%>%
  ggplot(aes(y=service, fill=provides))+
  geom_bar(stat="count")+ 
  scale_fill_manual(values = c("No" = "#44a5c2", "Yes" = "#ffae49")) +
  labs(x= "Count", y = "Service", fill = "Provides") +
  theme_light()


```

```{r desc_stats_pred}
# foreign born 

hist(catchment$for_app, breaks=50)

median(catchment$for_app) 
sd(catchment$for_app)
min(catchment$for_app)
max(catchment$for_app)

# unemployed

hist(catchment$unemp_app, breaks=50)
mean(catchment$unemp_app)
median(catchment$unemp_app)
sd(catchment$unemp_app)
min(catchment$unemp_app)
max(catchment$unemp_app)

# latinx

hist(catchment$latinx_app, breaks=50)
median(catchment$latinx_app)
mean(catchment$latinx_app)
sd(catchment$latinx_app)
min(catchment$latinx_app)
max(catchment$latinx_app)

# has a college degree
hist(catchment$bach_app, breaks=50)
median(catchment$bach_app)
mean(catchment$bach_app)
sd(catchment$bach_app)
min(catchment$bach_app) 
max(catchment$bach_app)

# female 
# 
# hist(catchment$fem_app, breaks=50)
# median(catchment$fem_app)
# mean(catchment$fem_app)
# sd(catchment$fem_app)
# min(catchment$fem_app)
# max(catchment$fem_app)

# language spoken at home is a language other than english 
hist(catchment$lang_app, breaks=50)
median(catchment$lang_app)
mean(catchment$lang_app)
min(catchment$lang_app)
max(catchment$lang_app)

# population 

hist(catchment$block_pop, breaks=50)
median(catchment$block_pop)
mean(catchment$block_pop)
sd(catchment$block_pop)
min(catchment$block_pop)
max(catchment$block_pop)

# poverty status 

hist(catchment$povtot_app, breaks=50)
median(catchment$povtot_app)
mean(catchment$povtot_app)
sd(catchment$povtot_app)
min(catchment$povtot_app)
max(catchment$povtot_app)


```

```{r logistic-reg}
log_tbl <- inner_join(catchment, web, by="NAME") %>% 
  dplyr::select(latinx_app, unemp_app, bach_app, for_app, white_app, fem_app, lang_app, block_pop, CIRC, VIST, HSPOT, CHBOOK, HHELP, IP_HHELP, CITCORNER, CYBNAV, UMEDIA)%>% 
  st_drop_geometry()

logistic <- glm(UMEDIA ~., data= log_tbl, family="binomial")

summary(logistic)

ggplot(grand_tbl, aes(x = bach_app, y = CIRC)) +
  geom_point(size = 2) +
  geom_text(aes(label = NAME), vjust = -1, size= 2)

```

```{r scatter-test}

ggplot(web, aes(x = VIST, y = CIRC)) +
  geom_point(size = 2) +
  geom_text(aes(label = NAME), vjust = -1, size= 2)
```

```{r join-web-catchment}
s.catchment <- catchment %>% select(NAME, GEOID, latinx_app, unemp_app, bach_app, for_app, white_app, black_app, asian_app, block_pop, povtot_app, geometry, lang_app)

n.catchment <- catchment.norm %>% select(NAME, GEOID,black_norm, white_norm, bach_norm, asian_norm, latinx_norm, unemp_norm, for_norm, lang_norm, pov_norm)

join_web <- full_join(n.catchment, web, by= "NAME")


```

```{r linear-regression}
reg.umedia <- glm(UMEDIA ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web, family = "binomial")

exp(coef(reg.umedia))

summary(reg.umedia)

reg.hspot <- glm(HSPOT ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web, family = "binomial")

exp(coef(reg.hspot))

summary(reg.hspot)

reg.chbook <- glm(CHBOOK ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web, family = "binomial")

exp(coef(reg.chbook))

summary(reg.chbook)

reg.mhss <- glm(MHSS ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web, family = "binomial")

exp(coef(reg.mhss))

summary(reg.mhss)

reg.citcor <- glm(CITCORNER ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web, family = "binomial")

exp(coef(reg.citcor))

summary(reg.citcor)


```
```{r traditiona-lgm}
# trad

reg.circ <- lm(CIRC ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.circ)

reg.vist <- lm(VIST ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.vist)

reg.compses <- lm(COMPSES ~ black_norm + asian_norm + for_norm + unemp_norm + latinx_norm + bach_norm + pov_norm , data = join_web)


summary(reg.compses)
```
# Discussion

Under construction. 

# Integrity Statement

The authors of this preregistration state that they completed this preregistration to the best of their knowledge and that no other preregistration exists pertaining to the same hypotheses and research.

This report is based upon the template for Reproducible and Replicable Research in Human-Environment and Geographical Sciences, DOI:[10.17605/OSF.IO/W29MQ](https://doi.org/10.17605/OSF.IO/W29MQ)

# References
Flitter, H., Weckenbrock, P., & Weibel, R. (n.d.). Thiessen Polygon. Retrieved December 16, 2023, from http://www.gitta.info/Accessibilit/en/html/UncProxAnaly_learningObject4.html
